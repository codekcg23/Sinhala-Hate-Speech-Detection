{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Resources\r\n",
    "\r\n",
    "https://drive.google.com/drive/folders/1VD8J-zYix3mD31jbIBhqK2fke-\r\n",
    "\r\n",
    "https://github.com/nlpcuom/WEIntrinsicEvaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Obectives\r\n",
    "\r\n",
    "1. Experiment CBOW and skip gram model with LOgistic regression\r\n",
    "2. Train own wor2vec\r\n",
    "3. Fine tuning word2vec "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Word2vec model with logistic regression\r\n",
    "\r\n",
    "size: The number of dimensions of the embeddings and the default is 100.\r\n",
    "\r\n",
    "window: The maximum distance between a target word and words around the target word. The default window is 5.\r\n",
    "\r\n",
    "min_count: The minimum count of words to consider when training the model; words with occurrence less than this count will be ignored. The default for min_count is 5.\r\n",
    "\r\n",
    "workers: The number of partitions during training and the default workers is 3.\r\n",
    "\r\n",
    "sg: The training algorithm, either CBOW(0) or skip gram(1). The default training algorithm is CBOW"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load modules and datasets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import neptune\r\n",
    "from neptunecontrib.monitoring.metrics import expand_prediction, log_class_metrics, log_binary_classification_metrics, log_classification_report,log_confusion_matrix,log_prediction_distribution\r\n",
    "from neptunecontrib.api import log_table\r\n",
    "import os\r\n",
    "from dotenv import load_dotenv\r\n",
    "\r\n",
    "load_dotenv()\r\n",
    "NEPTUNE_PROJECT= os.getenv('NEPTUNE_PROJECT')\r\n",
    "NEPTUNE_API_TOKEN = os.getenv(('NEPTUNE_API_TOKEN'))\r\n",
    "neptune.init(project_qualified_name= NEPTUNE_PROJECT,api_token=NEPTUNE_API_TOKEN) \r\n",
    "             "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.naive_bayes import MultinomialNB\r\n",
    "from sklearn.svm import SVC\r\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "#from sklearn.metrics import accuracy_score, f1_score, precision_score,roc_curve,roc_auc_score,confusion_matrix,recall_score\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "import re\r\n",
    "import gensim\r\n",
    "\r\n",
    "# import helper function script\r\n",
    "import sys\r\n",
    "sys.path.insert(1,'G:\\\\Github\\\\Sinhala-Hate-Speech-Detection')\r\n",
    "import utills"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# load datasets\r\n",
    "path = '../Datasets/processed/no_preprocessing/'\r\n",
    "df_A = pd.read_csv(path+'df_A.csv')    \r\n",
    "df_B = pd.read_csv(path+'df_B.csv')    # fb dataset -kaggle \r\n",
    "df_A_B = pd.read_csv(path+'df_A_B.csv') \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DBOW - Distributed bag of word"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from gensim.models.doc2vec import TaggedDocument\r\n",
    "train_tagged = train.apply(\r\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['narrative']), tags=[r.Product]), axis=1)\r\n",
    "test_tagged = test.apply(\r\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['narrative']), tags=[r.Product]), axis=1)\r\n",
    "train_tagged.values[30]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import multiprocessing\r\n",
    "\r\n",
    "cores = multiprocessing.cpu_count()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0, workers=cores)\r\n",
    "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%time\r\n",
    "for epoch in range(30):\r\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\r\n",
    "    model_dbow.alpha -= 0.002\r\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def vec_for_learning(model, tagged_docs):\r\n",
    "    sents = tagged_docs.values\r\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\r\n",
    "    return targets, regressorsdef vec_for_learning(model, tagged_docs):\r\n",
    "    sents = tagged_docs.values\r\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\r\n",
    "    return targets, regressors"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\r\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)\r\n",
    "\r\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\r\n",
    "logreg.fit(X_train, y_train)\r\n",
    "y_pred = logreg.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Distributed memory"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## \r\n",
    "model_dmm = Doc2Vec(dm=1, dm_mean=1, vector_size=300, window=10, negative=5, min_count=1, workers=5, alpha=0.065, min_alpha=0.065)\r\n",
    "model_dmm.build_vocab([x for x in tqdm(train_tagged.values)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%time\r\n",
    "for epoch in range(30):\r\n",
    "    model_dmm.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\r\n",
    "    model_dmm.alpha -= 0.002\r\n",
    "    model_dmm.min_alpha = model_dmm.alpha"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_train, X_train = vec_for_learning(model_dmm, train_tagged)\r\n",
    "y_test, X_test = vec_for_learning(model_dmm, test_tagged)\r\n",
    "\r\n",
    "logreg.fit(X_train, y_train)\r\n",
    "y_pred = logreg.predict(X_test)\r\n",
    "\r\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\r\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\r\n",
    "new_model = ConcatenatedDoc2Vec([model_dbow, model_dmm])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_vectors(model, tagged_docs):\r\n",
    "    sents = tagged_docs.values\r\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\r\n",
    "    return targets, regressors"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_train, X_train = get_vectors(new_model, train_tagged)\r\n",
    "y_test, X_test = get_vectors(new_model, test_tagged)\r\n",
    "\r\n",
    "logreg.fit(X_train, y_train)\r\n",
    "y_pred = logreg.predict(X_test)\r\n",
    "\r\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\r\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "print(model.wv.most_similar('ලැජ්ජයි'))\r\n",
    "print(model.wv.most_similar('මෑරෙන්න'))\r\n",
    "print(model.wv.most_similar('යකො'))\r\n",
    "print(model.wv.most_similar('හොරා'))\r\n",
    "print(model.wv.most_similar('බල්ලා'))\r\n",
    "print(model.wv.most_similar('තම්බි'))\r\n",
    "print(model.wv.most_similar('හුත්ති'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('ෂිකේ.', 0.624288022518158), ('දැක්කහමමචං', 0.606025218963623), ('අසරනට', 0.6009397506713867), ('ගානවාවල', 0.5993783473968506), ('තිලකයියේ', 0.5935572385787964), ('නාගෙනදඟලන්න', 0.5622760057449341), ('හිත්න්නත්', 0.5605373978614807), ('ආණ්දුව', 0.5562554597854614), ('්ගමයාවිලි', 0.5535441637039185), ('දැක්කම\\tපිනා', 0.5499239563941956)]\n",
      "[('හෑබෑමයි', 0.6853367686271667), ('වෙන්නජීවත්', 0.615235447883606), ('වෙලාවකඉපදුනේ', 0.5789225101470947), ('හෙටවෙයිද', 0.5657752752304077), ('ලෑස්තිවෙයල්ල', 0.5579881072044373), ('\\u200dබොම්බ', 0.5476895570755005), ('දෙයක්අන්ඩුවට', 0.5422118306159973), ('දෑක්කනම්', 0.5235146880149841), ('ෆොන්නඩෝටත්', 0.5233187675476074), ('වෑස්සටවත්', 0.5230247974395752)]\n",
      "[('යකෝ', 0.6215049624443054), ('පුරුන්ග', 0.5947710871696472), ('හොයපි', 0.5878672003746033), ('වේසික', 0.5774468779563904), ('සඳරුවණ්', 0.5767057538032532), ('බන්', 0.5762976408004761), ('පෑන්චියො', 0.5738309621810913), ('මේරටෙ', 0.5726816058158875), ('තිරිසනාතොපෙ', 0.572677731513977), ('දුශ්ඨයෙක්ට', 0.5710520148277283)]\n",
      "[('නටලාඅදින්', 0.6168825030326843), ('හොරු', 0.6146227121353149), ('හික්ස්මොනා', 0.6000667810440063), ('මනතරය', 0.5816130638122559), ('දැනේපුහුල්', 0.5782788395881653), ('සමහ\\u200dරැ', 0.572026252746582), ('ඇබිත්තයෙක්ද', 0.5686741471290588), ('කරුන්ක', 0.5661405324935913), ('සුරමුරලියවෙඩරු', 0.5654687881469727), ('ලේන්සුවක්ගුලිකොරපු', 0.5644397735595703)]\n",
      "[('බල්ලෙක්', 0.6643838882446289), ('බලු', 0.6198811531066895), ('ඉදපුවල්', 0.6177517175674438), ('යන්නෙත්නෑ', 0.6120303869247437), ('සමහරක්ටලොකු', 0.6097180843353271), ('හපාකෑවට', 0.6055284738540649), ('බ්ල්ලා', 0.6013304591178894), ('බල්ලන්', 0.6007422804832458), ('දීතුරුලට', 0.5996413826942444), ('බල්ලාගේ', 0.5994368195533752)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LR"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "X_train, X_test, Y_train, Y_test = utills.prepare_dataset(df_A, \"df_A\")"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'utills' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b3c080e9eec9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutills\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_A\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"df_A\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'utills' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def document_vector(model,doc):\r\n",
    "    \"\"\"Create document vectors by averaging word vectors. Remove out-of-vocabulary words.\"\"\"\r\n",
    "    doc = [word for word in doc if word in model.wv.vocab]\r\n",
    "    return np.mean(w2v[doc], axis=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train_avg_vec = [document_vector(model, doc) for doc in X_train ]#data.ingredients.apply(document_vector)\r\n",
    "X_test_avg_vec = [document_vector(model, doc) for doc in X_test ]    # test.ingredients.apply(document_vector)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = list(data['doc_vector'])\r\n",
    "X_test = list(test['doc_vector'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "clf = LogisticRegression(C=100)\r\n",
    "clf.fit(X_train_avg_vec, Y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_pred = clf.predict(X_test_avg_vec)\r\n",
    "utills.result(Y_test, y_pred)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# The train and test data was converted to list of strings since word2vec requires that\r\n",
    "#train_corpus = [\" \".join() for x in X_train]\r\n",
    "train_corpus = [x.split() for x in X_train]\r\n",
    "test_corpus = [x.split() for x in X_test]  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import gensim\r\n",
    "# let X be a list of tokenized texts (i.e. list of lists of tokens)\r\n",
    "# skip gram model - good for high morphological languafes\r\n",
    "model = gensim.models.Word2Vec(train_corpus, vector_size=300,window = 10,min_count=1,sg=1)\r\n",
    "print(model.wv)\r\n",
    "print(len(model.wv.vectors))\r\n",
    "w2v = dict(zip(model.wv.index_to_key, model.wv.vectors))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class MeanEmbeddingVectorizer(object):\r\n",
    "    def __init__(self, word2vec,size = 300):\r\n",
    "        self.word2vec = word2vec\r\n",
    "        # if a text is empty we should return a vector of zeros\r\n",
    "        # with the same dimensionality as all the other vectors\r\n",
    "        self.dim = size #len(word2vec.itervalues().next())\r\n",
    "\r\n",
    "    def fit(self, X, y):\r\n",
    "        return self\r\n",
    "\r\n",
    "    def transform(self, X):\r\n",
    "        return np.array([\r\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\r\n",
    "                    or [np.zeros(self.dim)], axis=0)\r\n",
    "            for words in X\r\n",
    "        ])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "unique, frequency = np.unique(Y_pred_w2v,  return_counts = True)\r\n",
    "print(unique,frequency)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lr = LogisticRegression()\r\n",
    "w2v_lr_pipe = Pipeline([('w2v', MeanEmbeddingVectorizer(w2v)), ('lr', lr)])\r\n",
    "\r\n",
    "\r\n",
    "w2v_lr_pipe.fit(X_train, Y_train)\r\n",
    "\r\n",
    "Y_pred_w2v = w2v_lr_pipe.predict(X_test)\r\n",
    "\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "print(classification_report(Y_test, Y_pred_w2v))\r\n",
    "\r\n",
    "utills.confusion_Matrix(Y_test,Y_pred_w2v)\r\n",
    "\r\n",
    "utills.PlotRocAuc(Y_test, Y_pred_w2v, \"green\", \"w2v_clf\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Use pretrained word2vec CBOW"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Use pretrained word2vec Skip gram"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## fine tuned pretrained one"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "new_model.build_vocab(df_A.comment.values, update = True)\r\n",
    "new_model.train(df_A.comment.values, total_examples=2, epochs = 1)\r\n",
    "new_model.wv.vocab"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train your own word2vec"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test with logistic regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Helper functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def classifier_feature(datasets,models,features):\r\n",
    "    final_result =pd.DataFrame(columns=['Accuracy','F1-score','Recall','Precision','AUC'])\r\n",
    "    for df_name,df in datasets.items():\r\n",
    "        df_result =pd.DataFrame(columns=['Accuracy','F1-score','Recall','Precision','AUC'])\r\n",
    "        X_train,X_test,Y_train,Y_test = utills.prepare_dataset(df,df_name)\r\n",
    "        for feature_name,feature in features.items():\r\n",
    "            feature_result =pd.DataFrame(columns=['Accuracy','F1-score','Recall','Precision','AUC'])\r\n",
    "            X_train_f,X_test_f = feature(X_train,X_test)\r\n",
    "            for model_name,model in models.items():\r\n",
    "                name = df_name + \"+\" + feature_name+ \"+\"+ model_name\r\n",
    "                print(name)\r\n",
    "                Y_pred = model(X_train_f,X_test_f,Y_train)\r\n",
    "                accuracy, f1_score, recall, precision, auc = result(Y_test,Y_pred)\r\n",
    "                final_result.loc[name] = [accuracy, f1_score, recall, precision, auc]\r\n",
    "                feature_result.loc[model_name] =[accuracy, f1_score, recall, precision, auc]\r\n",
    "                key =model_name + \"+\"+ feature_name\r\n",
    "                df_result.loc[key] = [accuracy, f1_score, recall, precision, auc]\r\n",
    "                log_result(Y_test,Y_pred,name,df_name,feature_name,model_name)\r\n",
    "            print(\" ==== \",feature_name ,\" ==== \")\r\n",
    "            display(feature_result)\r\n",
    "            log_table(feature_name,feature_result)\r\n",
    "        print(\" ==== \",df_name ,\" ==== \")\r\n",
    "        display(df_result)\r\n",
    "        log_table(df_name,df_result)\r\n",
    "    display(final_result)\r\n",
    "    log_table(name,final_result)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def bow_word(X_train,X_test):\r\n",
    "    bow = CountVectorizer(analyzer=\"word\", tokenizer=lambda text: text.split(),ngram_range=(1,2),lowercase=False)\r\n",
    "    bow.fit(X_train)\r\n",
    "    X_train_bow = bow.transform(X_train)\r\n",
    "    X_test_bow = bow.transform(X_test)\r\n",
    "\r\n",
    "    #print(bow.get_feature_names()[:20])\r\n",
    "    #print('The shape is', bow.shape)\r\n",
    "    # postion\r\n",
    "    #print(bow.vocabulary_)\r\n",
    "\r\n",
    "    return X_train_bow,X_test_bow"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def lr(X_train,X_test,Y_train):\r\n",
    "    lr = LogisticRegression(C=10,max_iter=350)\r\n",
    "    lr.fit(X_train,Y_train)\r\n",
    "    Y_pred = lr.predict(X_test)\r\n",
    "    return Y_pred"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_dict = {'df_A': df_A,'df_B': df_B,'df_C' :df_C,'df_D' :df_D,'df_A_B' :df_A_B,'df_A_C_D':df_A_C_D,'df_A_B_C':df_A_B_C,'df_A_B_D':df_A_B_D,'df_B_C_D':df_B_C_D,'df_all':df_all}\r\n",
    "# feature dict\r\n",
    "feature_dict={\"bow_word\":bow_word,\"bow_char\":bow_char,\"tfidf_word\":tfidf_word,\"tfidf_char\":tfidf_char}\r\n",
    "# model dict\r\n",
    "model_dict = {\"LR\":lr,\"SVC\":svc,\"MNB\":MNB}\r\n",
    "classifier_feature(df_dict, model_dict, feature_dict)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "fbbb7d2143a1d68e1cf272edf0974e702b621cb99b4ee39ce84db3bf0ffb588e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}